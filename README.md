<h1 align="center">Audio VLibras Desktop ğŸ—£ï¸ğŸ‘</h1>

<p align="center">
  Uma aplicaÃ§Ã£o Desktop que ouve sua voz, transcreve em tempo real e traduz para Libras utilizando o Avatar 3D oficial do governo.
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.x-blue?style=for-the-badge&logo=python" />
  <img src="https://img.shields.io/badge/AI-Faster_Whisper-green?style=for-the-badge" />
  <img src="https://img.shields.io/badge/Avatar-VLibras-yellow?style=for-the-badge" />
</p>

## :dart: Sobre o Projeto

Este projeto Ã© uma evoluÃ§Ã£o do visualizador web do VLibras. Ele encapsula o avatar em uma janela flutuante (**widget**) que fica sempre sobreposta a outras janelas, ideal para apresentaÃ§Ãµes, aulas e acessibilidade em tempo real.

O sistema utiliza:
1.  **Faster Whisper:** Para reconhecimento de fala offline de alta precisÃ£o.
2.  **API VLibras V2:** Para traduÃ§Ã£o gramatical correta (PortuguÃªs -> Glosa Libras).
3.  **PyWebView:** Para renderizar o avatar Unity em uma janela desktop leve.

## :sparkles: Funcionalidades

* ğŸ¤ **Reconhecimento de Voz:** CaptaÃ§Ã£o de Ã¡udio e transcriÃ§Ã£o automÃ¡tica a cada 3 segundos.
* ğŸ§  **TraduÃ§Ã£o Inteligente:** Converte frases do portuguÃªs para a estrutura gramatical de Libras (ex: "O gato comeu" -> "GATO COMER").
* ğŸ–¥ï¸ **Interface Responsiva:** Janela "Sempre no Topo" (Always on Top) com tela de carregamento.
* âš™ï¸ **Controles:** Ajuste de velocidade da animaÃ§Ã£o em tempo real.
* ğŸš€ **Performance:** LÃ³gica de fila e *debounce* para evitar atropelamento de sinais.

## :hammer_and_wrench: InstalaÃ§Ã£o e ExecuÃ§Ã£o

### PrÃ©-requisitos
* Python 3.8 ou superior instalado.
* Git instalado.

### Passo a Passo

1.  **Clone o repositÃ³rio:**
    ```bash
    git clone [https://github.com/KaazTiel/audio_vlibras_desktop.git](https://github.com/KaazTiel/audio_vlibras_desktop.git)
    cd audio_vlibras_desktop
    ```

2.  **Crie um ambiente virtual (Recomendado):**
    ```bash
    # Windows
    python -m venv venv
    .\venv\Scripts\activate

    # Linux/Mac
    python3 -m venv venv
    source venv/bin/activate
    ```

3.  **Instale as dependÃªncias:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Execute o projeto:**
    ```bash
    python main.py
    ```

> **Nota:** Na primeira execuÃ§Ã£o, o sistema irÃ¡ baixar automaticamente o modelo de IA do Whisper (aprox. 500MB a 1.5GB dependendo da versÃ£o). Isso pode levar alguns minutos.

## :gear: ConfiguraÃ§Ã£o TÃ©cnica

O projeto Ã© dividido em dois mÃ³dulos principais para facilitar a manutenÃ§Ã£o:

* `main.py`: Gerencia a interface grÃ¡fica, o servidor local do avatar e a ponte entre o Python e o Javascript.
* `reconhecimento.py`: MÃ³dulo isolado responsÃ¡vel por capturar o Ã¡udio do microfone e processar com o Faster Whisper.

---
Desenvolvido com ğŸ’™ para acessibilidade.
